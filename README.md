Facial Expression Recognition using CNN
ğŸ“Œ Project Overview

Facial Expression Recognition (FER) is a key component of Humanâ€“Computer Interaction (HCI) systems that enables machines to understand human emotions. This project implements a CNN-based facial expression recognition system enhanced with Digital Image Processing techniques to improve performance under real-world conditions such as lighting variation and noise.

â“ Why This Project?

Understanding facial expressions is essential for building intelligent, emotion-aware systems. This project was developed to gain hands-on experience in:

Image preprocessing and enhancement

Deep learning-based emotion classification

Handling real-world challenges in facial analysis

ğŸ¯ Objectives

Detect human faces from images

Classify facial expressions into emotion categories

Improve recognition accuracy using preprocessing techniques

ğŸ§  Technical Approach
Deep Learning

Convolutional Neural Network (CNN)

Implemented using TensorFlow and Keras

Digital Image Processing Techniques

Histogram Equalization (HE)

Contrast Limited Adaptive Histogram Equalization (CLAHE)

Local Binary Patterns (LBP)

Canny Edge Detection

Principal Component Analysis (PCA)

These techniques enhance contrast, extract facial features, and reduce noise before classification.

ğŸ§© Model Details

CNN model trained on grayscale facial images

Input image size: 48 Ã— 48

Multiple convolution and max-pooling layers used

Fully connected layers for classification

Softmax output layer for emotion prediction

âš™ï¸ Model Architecture

Input layer (48Ã—48 grayscale image)

Convolution + ReLU activation layers

Max Pooling layers

Fully Connected (Dense) layers

Softmax output layer

ğŸ“‚ Dataset Details

Facial expression image dataset (grayscale)

Images resized and normalized before training

Face detection performed using Haar Cascade Classifier

ğŸ“Š Performance & Results

Emotion prediction with confidence score

Example output:

Happy: 63.1%

Tested on unseen facial images for generalization


Sample Output

<img width="2484" height="1220" alt="image" src="https://github.com/user-attachments/assets/56d34a65-6421-41ef-9756-56bb39de9949" />

ğŸŒ Real-World Applications

Emotion-aware virtual assistants

Online learning engagement analysis

Mental health and stress monitoring

Customer sentiment analysis

Smart surveillance systems

âš ï¸ Limitations

Performance may reduce under extreme lighting conditions

Limited number of emotion classes

Accuracy depends on face alignment and image quality

## ğŸ› ï¸ Skills & Tools Used

| Category | Technologies |
|----------|-------------|
| Programming Language | Python |
| Deep Learning | Convolutional Neural Networks (CNN) |
| Frameworks | TensorFlow, Keras |
| Computer Vision | OpenCV |
| Image Processing | HE, CLAHE, LBP, Canny Edge Detection |
| Model Development | Model Training and Evaluation |
| Version Control | Git & GitHub |


â–¶ï¸ How to Run the Project

To download the project source code from GitHub to your local system, run the following command:
```bash
git clone https://github.com/your-username/Facial_Expression_Recognition.git
cd Facial_Expression_Recognition
```

To install all required libraries needed to run the project, execute the following command:
```bash
pip install tensorflow keras opencv-python numpy matplotlib
```

To start the facial expression recognition system, run the following command:
```bash
python main.py
```

## ğŸ“ Project Structure
```
Facial_Expression_Recognition/
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ model.h5
â”œâ”€â”€ haarcascade_frontalface_default.xml
â”œâ”€â”€ emotion-classification-cnn-using-keras.ipynb
â”œâ”€â”€ README.md
â”œâ”€â”€ Presentation.pdf
â””â”€â”€ Facial_Expression_Recognition_Report.pdf
```

ğŸš€ Future Enhancements

Real-time emotion detection using webcam

Improve accuracy using transfer learning

Support additional emotion classes

Deploy as a web or mobile application

ğŸ‘¨â€ğŸ’» Author

Balaji Sakthivel



